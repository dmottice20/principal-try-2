{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Basic packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Visualization packages.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Necessary variables for file exploration.\n",
    "DATA_DIR = 'data'\n",
    "TRANSFORMED_DIR = 'transformed'\n",
    "feature_file = 'transformed_features.csv'\n",
    "response_file = 'transformed_responses.csv'\n",
    "\n",
    "# Read in the data.\n",
    "feature_df = pd.read_csv('../{}/{}/{}'.format(DATA_DIR, TRANSFORMED_DIR, feature_file))\n",
    "response_df = pd.read_csv('../{}/{}/{}'.format(DATA_DIR, TRANSFORMED_DIR, response_file))\n",
    "feature_df.shape, response_df.shape\n",
    "\n",
    "# Convert date to str & set as index.\n",
    "feature_df['DATE'] = pd.to_datetime(feature_df['DATE'])\n",
    "feature_df.set_index('DATE', drop=True, inplace=True)\n",
    "response_df['Date'] = pd.to_datetime(response_df['Date'])\n",
    "response_df.set_index('Date', drop=True, inplace=True)\n",
    "\n",
    "# Normalize data frame.\n",
    "normalized_df = (feature_df - feature_df.mean()) / feature_df.std()\n",
    "\n",
    "# Perform a train-test split. Looking at the above data, let's train on all data prior to end of year 2005.\n",
    "# Test on all data from 2005 to end of year 2019\n",
    "# Keep beginning of 2020 through 2021 seperate for analysis and comparisons with other methods.\n",
    "dates = np.array(feature_df.index)\n",
    "# Add 1 to include December as a part of the train.\n",
    "training_ends = np.where(dates == pd.to_datetime(\"2009-12-01\"))[0][0] + 1\n",
    "test_ends = np.where(dates == pd.to_datetime(\"2019-12-01\"))[0][0] + 1\n",
    "X_train, X_test, X_analysis = normalized_df.iloc[:training_ends, :], normalized_df.iloc[training_ends:test_ends, :], normalized_df.iloc[test_ends:, :]\n",
    "y_train, y_test, y_analysis = response_df['Equity Indices Market'].iloc[:training_ends], response_df['Equity Indices Market'].iloc[training_ends:test_ends], response_df['Equity Indices Market'].iloc[test_ends:]\n",
    "X_train.shape, X_test.shape, X_analysis.shape\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)\n",
    "\n",
    "def graphHistory(history, title):\n",
    "    \"\"\"\n",
    "    Function for graphing the training and valiedation accuracy and loss\n",
    "    ...\n",
    "    :param history - history object from keras desired to plot.\n",
    "    :param title - str that will be the title of the resulting plot.\n",
    "    \"\"\"\n",
    "    # summarize history for accuracy\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    axes[0].plot(history.history['accuracy'])\n",
    "    axes[0].plot(history.history['val_accuracy'])\n",
    "    #axes[0].title('Model Accuracy ' + title)\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].legend(['Tr. Acc', 'Val. Acc'])\n",
    "\n",
    "    # summarize history for loss\n",
    "    axes[1].plot(history.history['loss'])\n",
    "    axes[1].plot(history.history['val_loss'])\n",
    "    #axes[1].title('Model Loss ' + title)\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].legend(['Tr. Loss', 'Val. Loss'])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Do the data transformations...\n",
    "n_steps = 12\n",
    "lstm_X_train, lstm_y_train = split_sequence(y_train, n_steps)\n",
    "lstm_X_test, lstm_y_test = split_sequence(y_test, n_steps)\n",
    "print(lstm_X_train.shape, lstm_y_train.shape, lstm_X_test.shape, lstm_y_test.shape)\n",
    "\n",
    "# Reshape from (samples, timesteps) to (samples, timesteps, features)\n",
    "n_features = 1\n",
    "lstm_X_train = lstm_X_train.reshape((lstm_X_train.shape[0], lstm_X_train.shape[1], n_features))\n",
    "lstm_X_test = lstm_X_test.reshape((lstm_X_test.shape[0], lstm_X_test.shape[1], n_features))\n",
    "print(lstm_X_train.shape, lstm_y_train.shape, lstm_X_test.shape, lstm_y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(204, 12) (204,) (108, 12) (108,)\n",
      "(204, 12, 1) (204,) (108, 12, 1) (108,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# define model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.LSTM(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics='accuracy')\n",
    "model.summary()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 12, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "history = model.fit(lstm_X_train, lstm_y_train, epochs=100, validation_data=(lstm_X_test, lstm_y_test), shuffle=False)\n",
    "graphHistory(history, 'Stacked LSTM')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "3/7 [===========>..................] - ETA: 0s - loss: 19.0738 - accuracy: 0.0000e+00"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/davidmottice/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4211: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7/7 [==============================] - 0s 67ms/step - loss: 21.8188 - accuracy: 0.0000e+00 - val_loss: 10.1196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 21.4897 - accuracy: 0.0000e+00 - val_loss: 9.9750 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 21.3508 - accuracy: 0.0000e+00 - val_loss: 9.8826 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 21.2912 - accuracy: 0.0000e+00 - val_loss: 9.8537 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 21.5728 - accuracy: 0.0000e+00 - val_loss: 9.8571 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 21.3633 - accuracy: 0.0000e+00 - val_loss: 9.8806 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 21.1878 - accuracy: 0.0000e+00 - val_loss: 9.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 21.5161 - accuracy: 0.0000e+00 - val_loss: 9.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.9321 - accuracy: 0.0000e+00 - val_loss: 10.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 20.9618 - accuracy: 0.0000e+00 - val_loss: 10.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 20.8856 - accuracy: 0.0000e+00 - val_loss: 10.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 20.7630 - accuracy: 0.0000e+00 - val_loss: 9.9870 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 20.4450 - accuracy: 0.0000e+00 - val_loss: 10.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 20.5510 - accuracy: 0.0000e+00 - val_loss: 10.0466 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 20.4291 - accuracy: 0.0000e+00 - val_loss: 10.1234 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 21.0536 - accuracy: 0.0000e+00 - val_loss: 10.2022 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 20.3762 - accuracy: 0.0000e+00 - val_loss: 10.2684 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 19.6198 - accuracy: 0.0000e+00 - val_loss: 10.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 19.7184 - accuracy: 0.0000e+00 - val_loss: 10.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 19.7762 - accuracy: 0.0000e+00 - val_loss: 10.6001 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 20.3378 - accuracy: 0.0000e+00 - val_loss: 10.5378 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 19.5342 - accuracy: 0.0000e+00 - val_loss: 10.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.1570 - accuracy: 0.0000e+00 - val_loss: 10.4606 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.8090 - accuracy: 0.0000e+00 - val_loss: 10.5535 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.5800 - accuracy: 0.0000e+00 - val_loss: 10.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 20.3385 - accuracy: 0.0000e+00 - val_loss: 10.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 20.3920 - accuracy: 0.0000e+00 - val_loss: 10.1945 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.5284 - accuracy: 0.0000e+00 - val_loss: 10.1954 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.2194 - accuracy: 0.0000e+00 - val_loss: 10.1872 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 20.1795 - accuracy: 0.0000e+00 - val_loss: 10.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 19.6631 - accuracy: 0.0000e+00 - val_loss: 10.2733 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 20.0389 - accuracy: 0.0000e+00 - val_loss: 10.3927 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 19.8802 - accuracy: 0.0000e+00 - val_loss: 10.5731 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 19.2799 - accuracy: 0.0000e+00 - val_loss: 10.6543 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 19.7592 - accuracy: 0.0000e+00 - val_loss: 10.7341 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 18.4446 - accuracy: 0.0000e+00 - val_loss: 10.8201 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 18.5291 - accuracy: 0.0000e+00 - val_loss: 10.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 19.2929 - accuracy: 0.0000e+00 - val_loss: 10.8131 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 19.5831 - accuracy: 0.0000e+00 - val_loss: 10.7737 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 19.0582 - accuracy: 0.0000e+00 - val_loss: 10.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 18.4955 - accuracy: 0.0000e+00 - val_loss: 10.6957 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 18.4935 - accuracy: 0.0000e+00 - val_loss: 10.8598 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 18.5207 - accuracy: 0.0000e+00 - val_loss: 11.0824 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 19.0616 - accuracy: 0.0000e+00 - val_loss: 11.3141 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 18.3605 - accuracy: 0.0000e+00 - val_loss: 10.8964 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 18.1302 - accuracy: 0.0000e+00 - val_loss: 11.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 17.4154 - accuracy: 0.0000e+00 - val_loss: 12.1513 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 18.9314 - accuracy: 0.0000e+00 - val_loss: 11.7775 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 18.6834 - accuracy: 0.0000e+00 - val_loss: 11.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 19.0167 - accuracy: 0.0000e+00 - val_loss: 11.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 18.0935 - accuracy: 0.0000e+00 - val_loss: 10.8905 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 18.3347 - accuracy: 0.0000e+00 - val_loss: 11.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 17.7287 - accuracy: 0.0000e+00 - val_loss: 11.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 17.6488 - accuracy: 0.0000e+00 - val_loss: 11.9299 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 16.6288 - accuracy: 0.0000e+00 - val_loss: 11.8265 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 16.9030 - accuracy: 0.0000e+00 - val_loss: 12.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 17.7061 - accuracy: 0.0000e+00 - val_loss: 12.2819 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 16.3983 - accuracy: 0.0000e+00 - val_loss: 11.9487 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 16.1800 - accuracy: 0.0000e+00 - val_loss: 11.8617 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 16.3798 - accuracy: 0.0000e+00 - val_loss: 12.7556 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 17.0072 - accuracy: 0.0000e+00 - val_loss: 12.0355 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 16.7197 - accuracy: 0.0000e+00 - val_loss: 11.7701 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 16.5164 - accuracy: 0.0000e+00 - val_loss: 12.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 15.3204 - accuracy: 0.0000e+00 - val_loss: 13.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 14.7956 - accuracy: 0.0000e+00 - val_loss: 13.7569 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 15.8438 - accuracy: 0.0000e+00 - val_loss: 12.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 16.3696 - accuracy: 0.0000e+00 - val_loss: 12.7988 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 15.6095 - accuracy: 0.0000e+00 - val_loss: 13.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 15.4990 - accuracy: 0.0000e+00 - val_loss: 12.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 13.8280 - accuracy: 0.0000e+00 - val_loss: 14.2478 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 15.6221 - accuracy: 0.0000e+00 - val_loss: 13.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 15.0130 - accuracy: 0.0000e+00 - val_loss: 13.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 14.8637 - accuracy: 0.0000e+00 - val_loss: 13.3045 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 14.5390 - accuracy: 0.0000e+00 - val_loss: 14.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 15.5082 - accuracy: 0.0000e+00 - val_loss: 13.8172 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 13.7235 - accuracy: 0.0000e+00 - val_loss: 13.5919 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 15.2174 - accuracy: 0.0000e+00 - val_loss: 12.3158 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 15.4942 - accuracy: 0.0000e+00 - val_loss: 11.8249 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 15.6177 - accuracy: 0.0000e+00 - val_loss: 12.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 14.1265 - accuracy: 0.0000e+00 - val_loss: 13.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 14.2172 - accuracy: 0.0000e+00 - val_loss: 13.9522 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 15.6491 - accuracy: 0.0000e+00 - val_loss: 12.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 15.9782 - accuracy: 0.0000e+00 - val_loss: 12.0577 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 15.1286 - accuracy: 0.0000e+00 - val_loss: 12.5525 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 14.8477 - accuracy: 0.0000e+00 - val_loss: 13.6486 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 14.8793 - accuracy: 0.0000e+00 - val_loss: 13.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 14.8683 - accuracy: 0.0000e+00 - val_loss: 13.6497 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 14.4626 - accuracy: 0.0000e+00 - val_loss: 13.9804 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 14.2906 - accuracy: 0.0000e+00 - val_loss: 14.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 14.0878 - accuracy: 0.0000e+00 - val_loss: 14.6650 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 15.5283 - accuracy: 0.0000e+00 - val_loss: 13.2418 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 14.5943 - accuracy: 0.0000e+00 - val_loss: 13.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 13.8603 - accuracy: 0.0000e+00 - val_loss: 13.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 13.0877 - accuracy: 0.0000e+00 - val_loss: 13.9700 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 13.2633 - accuracy: 0.0000e+00 - val_loss: 14.0515 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 12.5441 - accuracy: 0.0000e+00 - val_loss: 13.0608 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 14.7690 - accuracy: 0.0000e+00 - val_loss: 12.2001 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 13.4608 - accuracy: 0.0000e+00 - val_loss: 13.5218 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 14.6005 - accuracy: 0.0000e+00 - val_loss: 13.7480 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 14.1098 - accuracy: 0.0000e+00 - val_loss: 13.9042 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "##############################\n",
    "# Multi-variate Stacked LTSM #\n",
    "##############################\n",
    "# define a fx. to split a multivariate sequence into samples\n",
    "def split_sequences_mv(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Concat the X_train and y_train\n",
    "dataset = np.hstack((X_train.values, y_train.values.reshape((y_train.shape[0], 1))))\n",
    "test_data = np.hstack((X_test.values, y_test.values.reshape((y_test.shape[0], 1))))\n",
    "X_train.shape, y_train.shape, dataset.shape, type(dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((216, 58), (216,), (216, 59), numpy.ndarray)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "stacked_X_train, stacked_y_train = split_sequences_mv(dataset, 12)\n",
    "stacked_X_test, stacked_y_test = split_sequences_mv(test_data, 12)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Define the model...\n",
    "n_features = 58\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(32, activation='relu', kernel_initializer='he_normal', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(tf.keras.layers.LSTM(16, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mse', metrics='accuracy')\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 12, 32)            11648     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 14,801\n",
      "Trainable params: 14,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "history = model.fit(stacked_X_train, stacked_y_train, batch_size=4, epochs=100, validation_data=(stacked_X_test, stacked_y_test), shuffle=False)\n",
    "graphHistory(history, 'Multi-variate Stacked LSTM')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      " 3/52 [>.............................] - ETA: 2s - loss: 43.8731 - accuracy: 0.0000e+00"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/davidmottice/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4211: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "52/52 [==============================] - 3s 54ms/step - loss: 24.3086 - accuracy: 0.0000e+00 - val_loss: 15.5788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 22.4203 - accuracy: 0.0000e+00 - val_loss: 15.6845 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 20.0765 - accuracy: 0.0000e+00 - val_loss: 12.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 18.6923 - accuracy: 0.0000e+00 - val_loss: 16.0227 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 18.2084 - accuracy: 0.0000e+00 - val_loss: 16.4408 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 19.1140 - accuracy: 0.0000e+00 - val_loss: 15.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 17.4359 - accuracy: 0.0000e+00 - val_loss: 39.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 17.2342 - accuracy: 0.0000e+00 - val_loss: 23.8954 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 18.3970 - accuracy: 0.0000e+00 - val_loss: 14.1601 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 17.3262 - accuracy: 0.0000e+00 - val_loss: 20.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 17.4295 - accuracy: 0.0000e+00 - val_loss: 19.2078 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 16.9442 - accuracy: 0.0000e+00 - val_loss: 16.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 16.6616 - accuracy: 0.0000e+00 - val_loss: 17.3830 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 16.8458 - accuracy: 0.0000e+00 - val_loss: 15.9466 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 16.0105 - accuracy: 0.0000e+00 - val_loss: 17.5502 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 15.9341 - accuracy: 0.0000e+00 - val_loss: 17.3498 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 16.0320 - accuracy: 0.0000e+00 - val_loss: 18.0579 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 15.6642 - accuracy: 0.0000e+00 - val_loss: 18.3299 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 16.6637 - accuracy: 0.0000e+00 - val_loss: 17.6772 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 16.4252 - accuracy: 0.0000e+00 - val_loss: 22.9690 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 16.8647 - accuracy: 0.0000e+00 - val_loss: 18.1474 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 16.8457 - accuracy: 0.0000e+00 - val_loss: 24.0398 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 18.2139 - accuracy: 0.0000e+00 - val_loss: 22.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 17.2450 - accuracy: 0.0000e+00 - val_loss: 37.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 16.8809 - accuracy: 0.0000e+00 - val_loss: 20.6823 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 15.6333 - accuracy: 0.0000e+00 - val_loss: 24.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 14.9485 - accuracy: 0.0000e+00 - val_loss: 23.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 14.6216 - accuracy: 0.0000e+00 - val_loss: 25.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 15.7687 - accuracy: 0.0000e+00 - val_loss: 28.8624 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 3s 55ms/step - loss: 15.6363 - accuracy: 0.0000e+00 - val_loss: 32.7682 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 16.0152 - accuracy: 0.0000e+00 - val_loss: 32.6805 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 3s 56ms/step - loss: 15.4323 - accuracy: 0.0000e+00 - val_loss: 38.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 3s 57ms/step - loss: 15.2113 - accuracy: 0.0000e+00 - val_loss: 58.1637 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 15.3050 - accuracy: 0.0000e+00 - val_loss: 44.3577 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 3s 54ms/step - loss: 14.5484 - accuracy: 0.0000e+00 - val_loss: 52.5009 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 3s 58ms/step - loss: 14.3791 - accuracy: 0.0000e+00 - val_loss: 44.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "41/52 [======================>.......] - ETA: 0s - loss: 13.6625 - accuracy: 0.0000e+00"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k3/8c3mqv1s6lx59_xfcsfxgwhw0000gn/T/ipykernel_20334/3370102876.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgraphHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Multi-variate Stacked LSTM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# Run forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    789\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    367\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m       last_output, outputs, states = backend.rnn(\n\u001b[0m\u001b[1;32m   1158\u001b[0m           \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4499\u001b[0;31m       final_outputs = tf.compat.v1.while_loop(\n\u001b[0m\u001b[1;32m   4500\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4501\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4495\u001b[0m             ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))\n\u001b[1;32m   4496\u001b[0m         \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_new_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4497\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4499\u001b[0m       final_outputs = tf.compat.v1.while_loop(\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AFIT/principal-try-2/project-env/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    452\u001b[0m         _ctx, \"AddV2\", name, x, y)\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('project-env': venv)"
  },
  "interpreter": {
   "hash": "d13373dd3c7c2384c9c35d05f5096fd112f2e7fb5ec64c9f55217b2d4ec34c87"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}